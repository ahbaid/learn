{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Ahbaid Gaffoor\n",
    "# Date: Wednesday 26th April 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data with NumPy\n",
    "1. Load NOAAA station and temperature data from text files\n",
    "2. Integrate, smooth and plot data\n",
    "3. Compute daily records\n",
    "4. Challenge: Compare warmest year of cold location with coldest year of warm location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NOAA station and temperature data from text files\n",
    "1. Download file over ftp from http://www.ncdc.noaa.gov\n",
    "2. Parse a space-separated text file into a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "# seaborn is an extension to matplotlib to improve ddefault plot formatting and adds additional plot types\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instruct pyplot to keep plots inline with the notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('stations.txt', <email.message.Message at 0x114474ef0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to download files using python\n",
    "import urllib.request as urlreq\n",
    "urlreq.urlretrieve('ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt','stations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACW00011604  17.1167  -61.7833   10.1    ST JOHNS COOLIDGE FLD                       \\n',\n",
       " 'ACW00011647  17.1333  -61.7833   19.2    ST JOHNS                                    \\n',\n",
       " 'AE000041196  25.3330   55.5170   34.0    SHARJAH INTER. AIRP            GSN     41196\\n',\n",
       " 'AEM00041194  25.2550   55.3640   10.4    DUBAI INTL                             41194\\n',\n",
       " 'AEM00041217  24.4330   54.6510   26.8    ABU DHABI INTL                         41217\\n',\n",
       " 'AEM00041218  24.2620   55.6090  264.9    AL AIN INTL                            41218\\n',\n",
       " 'AF000040930  35.3170   69.0170 3366.0    NORTH-SALANG                   GSN     40930\\n',\n",
       " 'AFM00040938  34.2100   62.2280  977.2    HERAT                                  40938\\n',\n",
       " 'AFM00040948  34.5660   69.2120 1791.3    KABUL INTL                             40948\\n',\n",
       " 'AFM00040990  31.5000   65.8500 1010.0    KANDAHAR AIRPORT                       40990\\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample the first 10 lines of stations.txt\n",
    "# Observations:\n",
    "# 1. station code \n",
    "# 2. longitude and latitude\n",
    "# 3. sea level in meters\n",
    "# 4. a name\n",
    "# 5. Some stations are tagged with \"GSN\" - GCOS Surface Network\n",
    "#\n",
    "# Our focus will be on stations with the GSN tag\n",
    "#\n",
    "open('stations.txt','r').readlines()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read all lines, skip those that do not have the GSN flag\n",
    "stations = {}\n",
    "for line in open('stations.txt','r'):\n",
    "    if 'GSN' in line:\n",
    "        fields = line.split()\n",
    "        # Grab from station name (5th field) onwards separate by ' ' and concatenate into value of dictionary\n",
    "        # Key name is the station code\n",
    "        stations[fields[0]] = ' '.join(fields[4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that finds station codes by pattern name\n",
    "def findstation(s):\n",
    "    found = {code: name for code, name in stations.items() if s in name}\n",
    "    print (found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USW00022536': 'HI LIHUE WSO AP 1020.1 GSN 91165'}\n"
     ]
    }
   ],
   "source": [
    "findstation('LIHUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AR000087623': 'SANTA ROSA AERO GSN 87623', 'BLM00085207': 'SAN IGNACIO VELASCO GSN 85207', 'CO000080001': 'SAN ANDRES (ISLA)/S GSN 80001', 'CUM00078310': 'CABO SAN ANTONIO PINAR DEL GSN 78310', 'ECM00084008': 'SAN CRISTOBAL GSN 84008', 'FKM00088889': 'MOUNT PLEASANT GSN 88889', 'ID000096925': 'SANGKAPURA (BAWEAN GSN 96925', 'IV000065599': 'SASSANDRA GSN 65599', 'JM000078388': 'MONTEGO BAY/SANGSTE GSN 78388', 'MG000044259': 'CHOIBALSAN GSN 44259', 'MP000061990': 'PLAISANCE (MAURITIU GSN 61990', 'MY000096491': 'SANDAKAN GSN 96491', 'NH000091554': 'PEKOA AIRPORT (SANT GSN 91554', 'RP000098851': 'GEN. SANTOS GSN 98851', 'RQW00011641': 'PR SAN JUAN L M MARIN AP GSN 78526', 'RSM00023955': 'ALEKSANDROVSKOE GSN 23955', 'RSM00032061': 'ALEKSANDROVSK-SAHALINSKIJ GSN 32061', 'SP000008027': 'SAN SEBASTIAN - IGUELDO GSN 08027', 'SWM00002589': 'GOTSKA SANDON A GSN 02589', 'TOM00065352': 'MANGO/SANSANNE GSN 65352', 'TX000038915': 'CARSANGA GSN 38915', 'USW00012921': 'TX SAN ANTONIO INTL AP GSN HCN 72253', 'USW00023188': 'CA SAN DIEGO LINDBERGH FLD GSN 72290', 'VE000080450': 'SAN FERNANDO GSN 80450', 'VE000080462': 'SANTA ELENA DE UAIR GSN 80462'}\n"
     ]
    }
   ],
   "source": [
    "findstation('SAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USW00023188': 'CA SAN DIEGO LINDBERGH FLD GSN 72290'}\n"
     ]
    }
   ],
   "source": [
    "findstation('SAN DIEGO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RSM00030710': 'IRKUTSK GSN 30710'}\n"
     ]
    }
   ],
   "source": [
    "findstation('IRKUTSK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USW00014922': 'MN MINNEAPOLIS/ST PAUL AP GSN HCN 72658'}\n"
     ]
    }
   ],
   "source": [
    "findstation('MINNEAPOLIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will look at data from the 4 stations from LIHUE, SAN DIEGO, IRKUTSK and MINNEAPOLIS\n",
    "datastations = ['USW00022536','USW00023188','RSM00030710','MINNEAPOLIS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Temperature Data\n",
    "1. Parsing a fixed-field text file using np.genfromtxt\n",
    "2. Using ranges of NumPy datetime objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Files we will be working with for each datastation are:\n",
    "# ./RSM00030710.dly for IRKUTSK\n",
    "# ./USW00014922.dly for MINNEAPOLIS\n",
    "# ./USW00022536.dly for LIHUE\n",
    "# ./USW00023188.dly for SAN DIEGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORMAT OF DATA FILES (\".dly\" FILES)\n",
    "\n",
    "Source: ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt \n",
    "\n",
    "Each \".dly\" file contains data for one station.  The name of the file\n",
    "corresponds to a station's identification code.  For example, \"USC00026481.dly\"\n",
    "contains the data for the station with the identification code USC00026481).\n",
    "\n",
    "Each record in a file contains one month of daily data.  The variables on each\n",
    "line include the following:\n",
    "```\n",
    "------------------------------\n",
    "Variable   Columns   Type\n",
    "------------------------------\n",
    "ID            1-11   Character\n",
    "YEAR         12-15   Integer\n",
    "MONTH        16-17   Integer\n",
    "ELEMENT      18-21   Character\n",
    "VALUE1       22-26   Integer\n",
    "MFLAG1       27-27   Character\n",
    "QFLAG1       28-28   Character\n",
    "SFLAG1       29-29   Character\n",
    "VALUE2       30-34   Integer\n",
    "MFLAG2       35-35   Character\n",
    "QFLAG2       36-36   Character\n",
    "SFLAG2       37-37   Character\n",
    "  .           .          .\n",
    "  .           .          .\n",
    "  .           .          .\n",
    "VALUE31    262-266   Integer\n",
    "MFLAG31    267-267   Character\n",
    "QFLAG31    268-268   Character\n",
    "SFLAG31    269-269   Character\n",
    "------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USW00022536195002TMAX  256  0  256  0  256  0  267  0  217  0  228  0  256  0  272  0  256  0  256  0  256  0  244  0  256  0  256  0  244  0  244  0  250  0  256  0  239  0  250  0  256  0  256  0  267  0  261  0  267  0  267  0  261  0  261  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002TMIN  178  0  156  0  161  0  167  0  167  0  167  0  189  0  211  0  206  0  217  0  217  0  211  0  200  0  200  0  206  0  183  0  206  0  206  0  206  0  194  0  206  0  200  0  206  0  200  0  211  0  183  0  172  0  200  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002PRCP    0  0    0  0    0  0    0  0  737  0  406  0   36  0   38  0    0T 0    0T 0    0  0    0T 0   18  0    5  0   10  0   18  0   15  0    5  0    0T 0    0T 0   23  0   10  0    3  0   48  0    0T 0    0T 0    0T 0    5  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002SNOW    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0-9999   -9999   -9999   \\n',\n",
       " 'USW00022536195002SNWD    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0    0  0-9999   -9999   -9999   \\n']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIHUE - USW00022536\n",
    "# ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/readme.txt section \n",
    "\n",
    "open('USW00022536.dly','r').readlines()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['------------------------------\\n',\n",
       " 'Variable   Columns   Type\\n',\n",
       " '------------------------------\\n',\n",
       " 'ID            1-11   Character\\n',\n",
       " 'YEAR         12-15   Integer\\n',\n",
       " 'MONTH        16-17   Integer\\n',\n",
       " 'ELEMENT      18-21   Character\\n',\n",
       " 'VALUE1       22-26   Integer\\n',\n",
       " 'MFLAG1       27-27   Character\\n',\n",
       " 'QFLAG1       28-28   Character\\n',\n",
       " 'SFLAG1       29-29   Character\\n',\n",
       " 'VALUE2       30-34   Integer\\n',\n",
       " 'MFLAG2       35-35   Character\\n',\n",
       " 'QFLAG2       36-36   Character\\n',\n",
       " 'SFLAG2       37-37   Character\\n',\n",
       " '  .           .          .\\n',\n",
       " '  .           .          .\\n',\n",
       " '  .           .          .\\n',\n",
       " 'VALUE31    262-266   Integer\\n',\n",
       " 'MFLAG31    267-267   Character\\n',\n",
       " 'QFLAG31    268-268   Character\\n',\n",
       " 'SFLAG31    269-269   Character\\n',\n",
       " '------------------------------\\n']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('readme.txt','r').readlines()[98:121]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a function using np.genfrom text to return record data. **\n",
    "\n",
    "NumPy needs to be told:\n",
    "1. The file name \n",
    "2. The size of all the fields\n",
    "3. Which columns we wish to keep \n",
    "4. The type of all the fields \n",
    "5. Last the names that we want to give to all the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsefile(filename):\n",
    "    return np.genfromtxt(\n",
    "        filename,\n",
    "        delimiter = dly_delimiter,\n",
    "        usecols = dly_usecols,\n",
    "        dtype = dly_dtype,\n",
    "        names = dly_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 11, 4, 2, 4 maps to ID, YEAR, MONTH, ELEMENT\n",
    "# 5, 1, 1 maps to each value and it's three flags which repeat 31 times -> VALUE1(5) + 3 flags MFLAG1, QFLAG1, SFLAG1\n",
    "dly_delimiter = [11,4,2,4] + [5,1,1,1] * 31\n",
    "\n",
    "# We will not use all the columns, we will use year, month, element, or cols 1,2,3 from the delimeter spec\n",
    "# and the value columns 4 through 31 \n",
    "dly_usecols = [1,2,3] + [4*i for i in range(1,32)]\n",
    "\n",
    "# Field types\n",
    "dly_dtype = [np.int32, np.int32, (np.str,4)] + [np.int32] * 31\n",
    "\n",
    "# Field names. obs = observable\n",
    "dly_names = ['year','month','obs'] + [str(day) for day in range(1,31+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lihue=parsefile('USW00022536.dly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (1950, 2, 'TMAX', 256, 256, 256, 267, 217, 228, 256, 272, 256, 256, 256, 244, 256, 256, 244, 244, 250, 256, 239, 250, 256, 256, 267, 261, 267, 267, 261, 261, -9999, -9999, -9999),\n",
       "       (1950, 2, 'TMIN', 178, 156, 161, 167, 167, 167, 189, 211, 206, 217, 217, 211, 200, 200, 206, 183, 206, 206, 206, 194, 206, 200, 206, 200, 211, 183, 172, 200, -9999, -9999, -9999),\n",
       "       (1950, 2, 'PRCP', 0, 0, 0, 0, 737, 406, 36, 38, 0, 0, 0, 0, 18, 5, 10, 18, 15, 5, 0, 0, 23, 10, 3, 48, 0, 0, 0, 5, -9999, -9999, -9999),\n",
       "       ...,\n",
       "       (2015, 9, 'WT03', -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, 1, -9999, 1, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999),\n",
       "       (2015, 9, 'WT08', -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, 1, -9999, -9999, -9999, 1, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, 1, 1, -9999, -9999, -9999, -9999, -9999, -9999),\n",
       "       (2015, 9, 'WT10', -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, 1, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999, -9999)], \n",
       "      dtype=[('year', '<i4'), ('month', '<i4'), ('obs', '<U4'), ('1', '<i4'), ('2', '<i4'), ('3', '<i4'), ('4', '<i4'), ('5', '<i4'), ('6', '<i4'), ('7', '<i4'), ('8', '<i4'), ('9', '<i4'), ('10', '<i4'), ('11', '<i4'), ('12', '<i4'), ('13', '<i4'), ('14', '<i4'), ('15', '<i4'), ('16', '<i4'), ('17', '<i4'), ('18', '<i4'), ('19', '<i4'), ('20', '<i4'), ('21', '<i4'), ('22', '<i4'), ('23', '<i4'), ('24', '<i4'), ('25', '<i4'), ('26', '<i4'), ('27', '<i4'), ('28', '<i4'), ('29', '<i4'), ('30', '<i4'), ('31', '<i4')])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lihue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** IMPROVEMENTS: **\n",
    "\n",
    "1. We have a complex NumPy record array with all the information contained in the original file. We need to massage this data into a better form. \n",
    "2. The temperatures for all the days of the month sit on the same row, which is inconvienient because different months have different numbers of days. Instead, each day should have a separate row. \n",
    "3. We also want to associate each data point with a proper NumPy datetime object.\n",
    "\n",
    "We will first create a function to do these transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unroll(record):\n",
    "    '''\n",
    "    1. We begin by creating a range of dates that correspondes to a row. \n",
    "    2. We specify the beginning of the month by including only the year and the month in a string fed to the NumPy \n",
    "       datetime 64 object. \n",
    "    3. We then create a range of dates using NumPy arange starting at the start date, ending at the start date \n",
    "       plus one month. And, with a step of one day.\n",
    "    '''\n",
    "    startdate = np.datetime64('{}-{:02}'.format(record['year'],record['month']))\n",
    "    dates = np.arange(startdate, startdate + np.timedelta64(1,'M'), np.timedelta64(1,'D'))\n",
    "    \n",
    "    '''\n",
    "    Next, we are going to collect the data for the days from the record. \n",
    "    We need to specify the field for which we're going to extract the data. \n",
    "    We can do that by enclosing dates in enumerate by looping over an index and a date at the same time. \n",
    "    And, by using that index to build a name of the record called. \n",
    "    Last, divide each data point by ten since temperatures are specified in tens of degrees.\n",
    "    '''\n",
    "    rows = [(date,record[str(i+1)]/10) for i,date in enumerate(dates)]\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1950, 2, 'TMAX', 256, 256, 256, 267, 217, 228, 256, 272, 256, 256, 256, 244, 256, 256, 244, 244, 250, 256, 239, 250, 256, 256, 267, 261, 267, 267, 261, 261, -9999, -9999, -9999)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lihue[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(numpy.datetime64('1950-02-01'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-02'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-03'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-04'), 26.699999999999999),\n",
       " (numpy.datetime64('1950-02-05'), 21.699999999999999),\n",
       " (numpy.datetime64('1950-02-06'), 22.800000000000001),\n",
       " (numpy.datetime64('1950-02-07'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-08'), 27.199999999999999),\n",
       " (numpy.datetime64('1950-02-09'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-10'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-11'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-12'), 24.399999999999999),\n",
       " (numpy.datetime64('1950-02-13'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-14'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-15'), 24.399999999999999),\n",
       " (numpy.datetime64('1950-02-16'), 24.399999999999999),\n",
       " (numpy.datetime64('1950-02-17'), 25.0),\n",
       " (numpy.datetime64('1950-02-18'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-19'), 23.899999999999999),\n",
       " (numpy.datetime64('1950-02-20'), 25.0),\n",
       " (numpy.datetime64('1950-02-21'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-22'), 25.600000000000001),\n",
       " (numpy.datetime64('1950-02-23'), 26.699999999999999),\n",
       " (numpy.datetime64('1950-02-24'), 26.100000000000001),\n",
       " (numpy.datetime64('1950-02-25'), 26.699999999999999),\n",
       " (numpy.datetime64('1950-02-26'), 26.699999999999999),\n",
       " (numpy.datetime64('1950-02-27'), 26.100000000000001),\n",
       " (numpy.datetime64('1950-02-28'), 26.100000000000001)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unroll(lihue[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unroll(record):\n",
    "    '''\n",
    "    NumPy arange correctly returned the days of February. Instead of a list of tuples, we want to return a \n",
    "    proper NumPy record array we can modify the function to do that. \n",
    "    \n",
    "    We'll feed the list rolls to NumPy array and specify the property type. \n",
    "    \n",
    "    It's going to be the date in days followed by the value as a double procedure number.\n",
    "    '''\n",
    "    startdate = np.datetime64('{}-{:02}'.format(record['year'],record['month']))\n",
    "    dates = np.arange(startdate, startdate + np.timedelta64(1,'M'), np.timedelta64(1,'D'))\n",
    "    \n",
    "   \n",
    "    rows = [(date,record[str(i+1)]/10) for i,date in enumerate(dates)]\n",
    "    #return rows\n",
    "    return np.array(rows,dtype=[('date','M8[D]'), ('value','d')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(datetime.date(1950, 2, 1), 25.6),\n",
       "       (datetime.date(1950, 2, 2), 25.6),\n",
       "       (datetime.date(1950, 2, 3), 25.6),\n",
       "       (datetime.date(1950, 2, 4), 26.7),\n",
       "       (datetime.date(1950, 2, 5), 21.7),\n",
       "       (datetime.date(1950, 2, 6), 22.8),\n",
       "       (datetime.date(1950, 2, 7), 25.6),\n",
       "       (datetime.date(1950, 2, 8), 27.2),\n",
       "       (datetime.date(1950, 2, 9), 25.6),\n",
       "       (datetime.date(1950, 2, 10), 25.6),\n",
       "       (datetime.date(1950, 2, 11), 25.6),\n",
       "       (datetime.date(1950, 2, 12), 24.4),\n",
       "       (datetime.date(1950, 2, 13), 25.6),\n",
       "       (datetime.date(1950, 2, 14), 25.6),\n",
       "       (datetime.date(1950, 2, 15), 24.4),\n",
       "       (datetime.date(1950, 2, 16), 24.4),\n",
       "       (datetime.date(1950, 2, 17), 25.0),\n",
       "       (datetime.date(1950, 2, 18), 25.6),\n",
       "       (datetime.date(1950, 2, 19), 23.9),\n",
       "       (datetime.date(1950, 2, 20), 25.0),\n",
       "       (datetime.date(1950, 2, 21), 25.6),\n",
       "       (datetime.date(1950, 2, 22), 25.6),\n",
       "       (datetime.date(1950, 2, 23), 26.7),\n",
       "       (datetime.date(1950, 2, 24), 26.1),\n",
       "       (datetime.date(1950, 2, 25), 26.7),\n",
       "       (datetime.date(1950, 2, 26), 26.7),\n",
       "       (datetime.date(1950, 2, 27), 26.1),\n",
       "       (datetime.date(1950, 2, 28), 26.1)], \n",
       "      dtype=[('date', '<M8[D]'), ('value', '<f8')])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unroll(lihue[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we want to take all the months contained in a file and concatenate them together into a single NumPy record array. We also want to select a single observable, such as minimum temperature. For this we write a function getobs for get observable. We write a list comprehension containing the unrolled rows for each row of the parsed file. And, select only those that contain our desired observable and we'd feed this list to NumPy concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getobs(filename,obs):\n",
    "    return np.concatenate([unroll(row) for row in parsefile(filename) if row[2] == obs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(datetime.date(1950, 2, 1), 17.8),\n",
       "       (datetime.date(1950, 2, 2), 15.6),\n",
       "       (datetime.date(1950, 2, 3), 16.1), ...,\n",
       "       (datetime.date(2015, 9, 28), -999.9),\n",
       "       (datetime.date(2015, 9, 29), -999.9),\n",
       "       (datetime.date(2015, 9, 30), -999.9)], \n",
       "      dtype=[('date', '<M8[D]'), ('value', '<f8')])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getobs('USW00022536.dly','TMIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(datetime.date(1950, 2, 1), 25.6),\n",
       "       (datetime.date(1950, 2, 2), 25.6),\n",
       "       (datetime.date(1950, 2, 3), 25.6), ...,\n",
       "       (datetime.date(2015, 9, 28), -999.9),\n",
       "       (datetime.date(2015, 9, 29), -999.9),\n",
       "       (datetime.date(2015, 9, 30), -999.9)], \n",
       "      dtype=[('date', '<M8[D]'), ('value', '<f8')])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getobs('USW00022536.dly','TMAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(datetime.date(1950, 2, 1), 0.0), (datetime.date(1950, 2, 2), 0.0),\n",
       "       (datetime.date(1950, 2, 3), 0.0), ...,\n",
       "       (datetime.date(2015, 9, 28), -999.9),\n",
       "       (datetime.date(2015, 9, 29), -999.9),\n",
       "       (datetime.date(2015, 9, 30), -999.9)], \n",
       "      dtype=[('date', '<M8[D]'), ('value', '<f8')])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getobs('USW00022536.dly','PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
